{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inventory Optimization Calculation\n",
    "\n",
    "This notebook is based on `EDA_InventoryOptimization.ipynb` and `CheckItems_bySubCategory.ipynb`, included all calculations within these two notebook, but NO PLOT. Just generate new CSV files.  \n",
    "\n",
    "#### Input Dataset Description\n",
    "1. `Distribution Report - Auckland Departures - July19.csv` \n",
    "2. `sales_newzealand.csv`: monthly sale data (**April-Sep**) (half year, with the middle month is July)\n",
    "3. `SubCateogoryInfo.csv`\n",
    "4. `Vendor_info.csv`\n",
    "\n",
    "\n",
    "## Contents\n",
    "1. Identify items which have potential issues (Output csv in **`Output/IssuedItem` folder**)\n",
    "\n",
    "2. **Capacity adjustment**\n",
    "   - `ProposedDepth` = 3, if Depth >= 4. Otherwise empty; \n",
    "   - `VarianceDepth` = ProposedDepth - Depth (should be negative)\n",
    "2. Identify Items which satisfy the rule in at least in one month (Output csv in **`AtleastOneMonth` folder**)\n",
    "   \n",
    "3. Identify Items which satisfy the rule in every month (Output csv in **`full_month` folder**)\n",
    "\n",
    "***\n",
    "### Explaination\n",
    "#### Identify items which have potential issues\n",
    "1. `New_items`,  `Removed_items`, `Check_items` will removed from the inventory analysis: \n",
    "    1. New_items\n",
    "       - The items are not in `distribution report`, but have sale history from July-Sep\n",
    "       - save them to `new_SKU.csv`\n",
    "    2. Removed_items\n",
    "       - The items are in `distribution report`, but have no sales from July-Sep\n",
    "       - save them to `removed_SKU.csv`\n",
    "    3. Check_items \n",
    "       - The items are in `distribution report`, but have no sales from Apr-Sep\n",
    "       - save them to `check_SKU.csv`\n",
    "       - There might be two reasons for this collection\n",
    "          1. file has not been update\n",
    "          2. the items are truly in the store, but cannot sold out \n",
    "    4. Incorrect_record_items\n",
    "       - The items has extremely high ratio of capacity/facing. (>6)\n",
    "       - Either facing or capacity is incorrect. Need to report to store manager.\n",
    "       - Save them in `Incorrect_record_items.csv`\n",
    "    5. Items Depth < 2 (same as Capacity < Facings *2)\n",
    "       - e.g. Capacity = Facings = 1, incorrect\n",
    "       - e.g Facing = 3, Capacity = 5, incorrect\n",
    "       - Capacity should > Facing. \n",
    "       - Save them in `Depth2_items.csv`\n",
    "       \n",
    "#### At least one month SKU\n",
    "Items which satisfy the rule in at least in one month from July, to Sep.\n",
    "- adjusted SKU(atLeastOneMonth): items which depth >=4, and has new proposed depth. save in `adjusted_SKU.csv`\n",
    "- unadjusted SKU(atLeastOneMonth): items which depth <4, and has no influnece under new rules. save in `unadjusted_SKU.csv`\n",
    "\n",
    "#### Full month (3 month) SKU\n",
    "Items satisfy the rule in every month (e.g. July, Aug, Sep)\n",
    "Save in `qty_less_than_capacity_all_month_SKU.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local appName=Inventory Opti Model>\n",
      "2.4.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from Inventory_opti_helperFunction import *\n",
    "import findspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import *\n",
    "# Import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "import re\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "\"\"\"\n",
    "Build the SparkSession\n",
    "\"\"\"\n",
    "# getOrCreate(): get the current Spark session or to create one if there is none running\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Inventory Opti Model\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "sc = spark.sparkContext # create a SparkSession object from your SparkContext\n",
    "\n",
    "# Verify SparkContext\n",
    "print(sc)\n",
    "\n",
    "# Print Spark version\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path of 6 month sales data, \n",
      "    e.g. ../data/RawData/sales_newzealand.csv:../data/RawData/sales_newzealand.csv\n",
      "Enter the path of disrtibuted report data, \n",
      "    e.g. ../data/RawData/Distribution Report - Auckland Departures - July19.csv or ../data/RawData/Distribution Report- Auckland Departures - Jan2020.csv:../data/RawData/Distribution Report- Auckland Departures - Jan2020.csv\n",
      "Input start date, e.g. 2019-04-01: 2019-06-01\n",
      "Input start date, e.g. 2019-10-01: 2019-12-01\n",
      "Enter the month begin to test, e.g. 7\n",
      "    Note that this month must included in sales data , and between start_date and end_date:9\n",
      "\n",
      "\n",
      "\n",
      "Find 0 Removed items, save them in Output/IssuedItem/removed_SKU.csv\n",
      "Find 108 New items, save them in Output/IssuedItem/new_SKU.csv\n",
      "Find 80 checked items, save them in Output/IssuedItem/checked_SKU.csv\n",
      "Find 122 Incorrect_record_items, save them in Output/IssuedItem/Incorrect_record_items.csv\n",
      "Find 21 Depth < 2 items, save them in Output/IssuedItem/Depth2_items.csv\n",
      "Save adjusted SKU(atLeastOneMonth) to Output/atLeastOneMonth/adjusted_SKU.csv\n",
      "Save unadjusted SKU(atLeastOneMonth) to Output/atLeastOneMonth/unadjusted_SKU.xlsx\n",
      "Save fullMonth SKU to Output/fullMonth/qty_less_than_capacity_all_month_SKU.csv\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "## read, merge and clean datasets\n",
    "#################################\n",
    "\n",
    "### User Input from interface\n",
    "sales_data_path, dist_data_path, start_date, end_date, split_month = user_put()\n",
    "\n",
    "\n",
    "month_merge, month_merge_early, month_merge_late, dist_df = read_merge_and_clean_data(sales_data_path, \n",
    "                                                                             dist_data_path, split_month, \n",
    "                                                                             start_date, end_date, spark)\n",
    "\n",
    "##############################################\n",
    "## Identify items with potential issues\n",
    "##############################################\n",
    "\n",
    "df = Identify_and_output_issused_items(month_merge, month_merge_early, month_merge_late, dist_df)\n",
    "df.toPandas().to_csv('../data/CleanedData/month_merge_total.csv', \n",
    "                             index=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "#############################\n",
    "### Analysis\n",
    "#############################\n",
    "names = [\"totalMonthlyNetSale\", \"totalMonthlyQtySold\", \"Price\", \n",
    "         \"SellMargin\", \"Facings\", \"Capacity\"]\n",
    "df = convertColumn(df, names, FloatType())\n",
    "\n",
    "\"\"\"\n",
    "Add more columns\n",
    "\"\"\"\n",
    "# add mean, std and geometric mean of qty sold GROUPBY subcategory and month to datatset \n",
    "df = calculate_mean_std_and_geometric_mean(df)\n",
    "# add capacity/sale ratio to dataset\n",
    "df = calculate_Capacity_to_sales(df)\n",
    "# add depth, proposed depth\n",
    "df = calculate_Depths(df)\n",
    "\n",
    "# find and analysis atLeastOneMonth_SKU\n",
    "df_atLeastOneMonth, unchanged_SKU, changed_SKU = find_and_analysis_atLeastOneMonth_SKU(df)\n",
    "Group_and_save_atLeastOneMonth_SKU(unchanged_SKU, changed_SKU)\n",
    "\n",
    "# find and analysis fullMonth SKU \n",
    "full_month_SKU_info = find_and_analysis_fullMonth_SKU(df_atLeastOneMonth, split_month, spark)\n",
    "save_fullMonth_SKU(full_month_SKU_info)\n",
    "\n",
    "print(\"Finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
